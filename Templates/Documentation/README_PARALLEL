=======================================================================================
 EsoMPI README
 V. 1.01
 GM 8/9/2017
=======================================================================================


=======================================================================================
	RUNNING THE CODE
=======================================================================================

 The parallel driver to use ESTM in HTC mode requires the following steps to be run.

1. copy the code root to the directory where you are going to run it. The code root
   includes two directories, src and Templates. Code is on github, EsoMPI branch

2a.  -copy src/EsoMPIsetup.bash from in the code root.

     -exec EsoMPIsetup; sintax is
       ./EsoMPIsetup.bash WorkDir
      the shell will copy all needed python source files in your WorkDir 
      (can be different from the code root; must exist)
      - in your WorkDir, edit the file coderoot.py and change the 
      code_root_dir to the appropriate value. It is the string after the instruction
      return in function coderoot(), trailing / is mandatory. MUST be a full path name.

   OR

2b. copy src/coderoot.py and sr/parallel.py in your WorkDir. 
    Change  code_root_dir to the appropriate value. It is the string after the instruction
    return in function coderoot(), trailing / is mandatory. MUST be a full path name.
    parallel.py will do the job for you.

3. put a file named input.txt in your WorkDir. This file contains all
   the parameters on which the driver will cycle. In the current setup
   it must have four columns:
   press ecc incl sma

   press: pressure IN UNITS OF EARTH ATMOSPHERIC PRESSURE
   ecc: eccentricity
   incl: rotation axis inclination (degrees)
   sma: semi-major axis (in AU)

   the file can contain as many lines as you want.
   an example of input.txt creator is make_input.py in Templates/Documentation

   DISCLAIMER: THE INPUT.TXT FILE WILL CHANGE WHILE WE ADD NEW PARAMETERS 

4. Verify that all needed python modules are installed on the system.
   If not, you must create a virtual environment that includes them.
   A shell example that does this for you is in Templates/Documentation
   and is named make_virtualenv.bash
   Requires virtualenv to exist. If not, contact your helpdesk. Python is needed
   for the ESTM code :-)

5. launch the code. a typical sintax could be:
   mpirun -np 4 python ./parallel.py

   Warning: the number of processor MUST be larger than 1, and smaller than
   the number of cases (number of lines in input.txt)

   If you have to use a queue manager, an example script is go_esoclimi
   in Template/Documentation. Uses PBS. Uses the code root as the working
   directory, a virtual environment (that must already have been set up).
   

6. During the execution:
   - you can create an empty file named "stop". The code will stop.
     (WARNING: untested)
   - the code writes a restart file each 300 seconds. if the code
     does not complete your list of cases, you can run it again, and it
     will use the file "restart.dat" instead of input.txt to complete
     your sample (WARNING: UNTESTED)
   - the code will stop anyway after 6 hours (you can change this by
     changing stop_time in parallel.py)
   - a list of completed cases can be found in the file "executed_out.dat"

   - you will find a number of dirs, named "0", "1".. "N" where N is the
     number of required runs, in your WrokDir. 
     They are work sub-directories in which each
     core is executing ESTM separately. They are deleted after each ESTM
     runs completes.  Under each dir, you will find Src, where all
     the needed files to compile the instance of ESTM are; and Src/Risultati
     where results are being written.

   - you will have a number of files run_0.log, run_1.log, ... run_M.log.
     These contain the logging of what each core is doing. They will remain
     after the run is completed


7. After the execution you will have the following results, in your WorkDir:
      RisultatiMultipli  will contain the full ESTM results in one directory per 
                         parameter set (its name is built from the used parameters)
      LogFiles           will contain the full ESTM screen output
      Database           will contain the FITS file of CONVERGED runs
      Thumbnails         will contains png thumbnails of latitude/time/temperature
                         plots during the last orbit, of CONVERGED runs
   
   Moreover, you sill find four files:

    SnowBall-Params.dat , RunawayGreenhouse-Params.dat , PressExceeded-Params.dat , IntegrationError-Params.dat

   They will contain the list of cases (one line per case containing the parameter set)
   where the corresponding exception happened during the run.


8. If you need to re-run the same case list in the same WorkDir, you'll have 
    to delete all of the output directories. The shell "clean", in Templates/Documentation,
    makes this for you. WARNING: your results will be lost.
    IF some core working sub-directory has been left, you will have to delete them
    by hands




=======================================================================================
	GENERAL PARALLEL STRUCTURE OF THE CODE
=======================================================================================

It's a typical master/slave code. Rank 0 is the master; you can have as many
slaves as you want.

The scheme is the following:

MASTER:  
  - executes the general setup (preparation of WorkDir,
    copy of python source files etc)
  - Collects a 'READY' mpi message from all slaves.
  - Starts the workers, sending them one line of parameters
    from the input file with a 'START' message. 
  - If there are more workers then lines, fires the unneeded ones
    sending them an 'EXIT' message

  Here an endless loop stars. It:
  - Sends a 'GO' message to all workers
  - Waits a 'DONE' messages and send back a 'NCDS' request 
    (non-converging data send)
  - Upon receiving a 'NCD' message with the data:
     * Updates the list of parameter that didn't converge
     * Checks if more input lines are present:
       - if YES, sends back a 'START' message with the new
         input line
       - if NO, exits the endless loop

  Here a cycle on the number of (not-fired) workers begin:
  - Waits for a 'DONE' message (workers are completing their 'START's).
  - Sends a 'NCDS' request.
  - Upon receiving an 'NCD' with data, updates non-converged parameter list
  - Sends an 'EXIT' message
  - Waits for an acknowledge (an 'EXIT' back)
    Upon receiving it, the number of released worker is incremented
  - When all workers are released, cycle ends

  At this point, non-converged parameter lists and overall summary
  are written on files and the code ends.

SLAVES:
  Start and endless loop
  - First they send 'READY' to the master.
  - Wait for a 'GO' message.
  - Execute for the first time 'START' or 'EXIT'
  - Send back a 'DONE' message when code finishes
  - Receive an 'NCDS' request; send the non-converging
    data to the master with an 'NCD' message
  - They can get back another 'START' or an 'EXIT'
     * if 'START', they  run code, send back 'DONE'
       and the cycle is repeated
     * if 'EXIT', they send back and 'EXIT' message and terminate.


  During their 'START' tasks, workers make the following operations ( inside the function esoclimi() ):
  - prepare the work area. A directory named after the simulation number
    is created, files from Templates/Std are copied, a sub-dir named 'Risultati'
    is created. All other needed files are copied
  - compliles ESTM
  - runs ESTM
  - tries to run tAtmo (Michele's atmospheric thickness code)
  - tries to produce FITS files (already in their Database dir)
    and Thumbnails (aready in the corresponding dir)
  - reads 'valori.txt' in Risultati, and sets up the appropriate 
    non-converged parameter lists if needed
  - archives Risultati in RisultatiMultipli at the WorkDir level
  - the same for the log file
  - returns the non-converged param list (can and hopefully be void!)

   In EsoParallelFlow.pdf (Templates/Documentation) you have a schematic 
   view of the communications.




=======================================================================================
	DETAILED DESCRIPTION OF CODE FUNCTIONS
=======================================================================================
  ...Giuliano mi aiuti qui?


